# HireLens AI

**Production-Grade AI-Powered Hiring Intelligence Platform**

HireLens AI helps recruiters and hiring managers see beyond resumes. The platform uses semantic matching and explainable AI to score and rank candidates, providing transparent, actionable insights for hiring decisions.

## ğŸ¯ Product Vision

HireLens AI is not a demo or tutorial project. It's a **real-world, enterprise-grade** platform designed for production use by recruiters at scale.

### Core Capabilities

- âœ… **Resume Parsing**: Extract structured data from PDF/DOCX resumes
- âœ… **Job Description Intelligence**: Parse and understand job requirements
- âœ… **Semantic Matching**: AI-powered candidate-job matching
- âœ… **Multi-Dimensional Scoring**: Skill match, experience, projects, domain familiarity
- âœ… **Explainable AI**: Human-readable explanations for every match
- âœ… **Candidate Ranking**: Percentile-based ranking with confidence levels
- âœ… **Recruiter Dashboard**: Interactive UI with tabs, modals, and drag-drop features
- âœ… **Job Management**: Create and manage job descriptions with AI-powered parsing
- âœ… **Resume Upload**: Drag-and-drop resume upload with automatic parsing
- âœ… **Candidate Management**: Add and manage candidates with resume linking
- âœ… **Interactive Rankings**: View AI-powered candidate rankings with detailed explanations

## ğŸ—ï¸ Architecture

### High-Level Overview

```
Frontend (Next.js) â†’ API Gateway (FastAPI) â†’ Services â†’ Database (PostgreSQL) + Cache (Redis)
                                                          â†“
                                                    Celery Workers (Async Tasks)
```

### Architecture Style

- **Phase 1**: Modular Monolith (current)
- **Phase 2**: Microservices-ready (documented)

See [Architecture Documentation](./docs/architecture.md) for detailed architecture.

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- Python 3.11+ (for local development)
- Node.js 18+ (for frontend development)
- **OpenAI API Key (Optional)** - Only needed if using OpenAI. Hugging Face works locally without API!

### Using Docker Compose (Recommended)

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd hirelens-ai
   ```

2. **Set up environment variables**
   ```bash
   # .env file already exists with default settings
   # Edit .env and configure:
   # - AI_PROVIDER=auto (uses Hugging Face locally, no API costs!)
   # - OPENAI_API_KEY (optional, only if you want to use OpenAI)
   ```

3. **Start services**
   ```bash
   docker-compose up -d
   ```

4. **Initialize database**
   ```bash
   docker-compose exec backend python backend/scripts/init_db.py
   ```

5. **Access the application**
   - Frontend: http://localhost:3000
   - API Docs: http://localhost:8000/api/docs
   - Backend API: http://localhost:8000

### Dashboard Features

The recruiter dashboard includes:

- **Jobs Tab**: View all jobs, create new jobs with AI-powered parsing
- **Candidates Tab**: Upload resumes (drag & drop), add candidates, view candidate list
- **Rankings Tab**: View AI-powered candidate rankings for selected jobs
- **Interactive Modals**: 
  - Job creation form with full job description parsing
  - Resume upload with drag-and-drop support
  - Candidate creation form with resume linking
- **Match All**: Bulk match all candidates to a job with one click
- **AI Explanations**: View detailed AI analysis with strengths, weaknesses, and recommendations

### Default Credentials

- **Email**: rohitravikantrane@gmail.com
- **Password**: admin123

âš ï¸ **Change these in production!**

## ğŸ“ Project Structure

```
hirelens-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ auth/           # Authentication & RBAC
â”‚   â”‚   â”œâ”€â”€ resumes/        # Resume processing
â”‚   â”‚   â”œâ”€â”€ jobs/           # Job description intelligence
â”‚   â”‚   â”œâ”€â”€ candidates/     # Candidate management
â”‚   â”‚   â”œâ”€â”€ matching/       # Matching & scoring engine
â”‚   â”‚   â”œâ”€â”€ ai_engine/      # AI reasoning engine
â”‚   â”‚   â”œâ”€â”€ core/           # Core utilities
â”‚   â”‚   â”œâ”€â”€ models/         # Database models
â”‚   â”‚   â”œâ”€â”€ tasks/          # Async Celery tasks
â”‚   â”‚   â””â”€â”€ main.py         # FastAPI application
â”‚   â”œâ”€â”€ scripts/            # Utility scripts
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/                # Next.js app directory
â”‚   â”‚   â”œâ”€â”€ dashboard/      # Main dashboard with tabs
â”‚   â”‚   â””â”€â”€ login/          # Login page
â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”‚   â”œâ”€â”€ JobModal.tsx    # Job creation modal
â”‚   â”‚   â”œâ”€â”€ ResumeUpload.tsx # Resume upload with drag-drop
â”‚   â”‚   â””â”€â”€ CandidateModal.tsx # Candidate creation form
â”‚   â”œâ”€â”€ lib/                # Utilities
â”‚   â”œâ”€â”€ hooks/              # React hooks
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md     # System architecture
â”‚   â”œâ”€â”€ ai_reasoning.md     # AI explainability
â”‚   â””â”€â”€ scaling.md         # Scaling strategy
â”œâ”€â”€ docker-compose.yml      # Docker orchestration
â””â”€â”€ README.md
```

## ğŸ” Authentication & RBAC

### Roles

- **Admin**: Full system access
- **Recruiter**: Manage jobs, candidates, resumes, view matches
- **Hiring Manager**: Read-only access to insights

### API Authentication

All API endpoints (except `/api/v1/auth/*`) require authentication:

```bash
curl -H "Authorization: Bearer <token>" http://localhost:8000/api/v1/jobs/
```

## ğŸ“Š Core Features

### 1. Resume Processing

Upload resumes (PDF/DOCX) and extract:
- Skills
- Experience (years, roles, companies)
- Education
- Projects
- Certifications

**API Example:**
```bash
curl -X POST http://localhost:8000/api/v1/resumes/upload \
  -H "Authorization: Bearer <token>" \
  -F "file=@resume.pdf"
```

### 2. Job Description Intelligence

Create job descriptions and extract:
- Required skills
- Nice-to-have skills
- Experience requirements
- Seniority level
- Education requirements

**API Example:**
```bash
curl -X POST http://localhost:8000/api/v1/jobs/ \
  -H "Authorization: Bearer <token>" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Senior Backend Engineer",
    "company": "Tech Corp",
    "raw_text": "We are looking for a senior backend engineer..."
  }'
```

### 3. AI Matching & Scoring

Match candidates to jobs with:
- **Overall Score** (0-100)
- **Skill Match Score** (40% weight)
- **Experience Score** (25% weight)
- **Project Similarity** (20% weight)
- **Domain Familiarity** (15% weight)

**API Example:**
```bash
curl -X POST "http://localhost:8000/api/v1/matching/match?candidate_id=1&job_id=1" \
  -H "Authorization: Bearer <token>"
```

### 4. Explainable AI

Every match includes:
- **Summary**: Overall assessment
- **Strengths**: 3-5 specific positive points
- **Weaknesses**: 3-5 gaps or concerns
- **Recommendations**: 2-3 actionable items
- **Confidence Level**: High/Medium/Low

See [AI Reasoning Documentation](./docs/ai_reasoning.md) for details.

### 5. Candidate Ranking

Get ranked candidates for a job:

```bash
curl "http://localhost:8000/api/v1/matching/job/1/rankings" \
  -H "Authorization: Bearer <token>"
```

Returns candidates sorted by match score with percentile rankings.

## ğŸ§  AI Engine

### AI Providers Supported

**1. Hugging Face (Recommended - Free & Local)**
- âœ… **Free** - No API costs
- âœ… **Local** - Runs on your machine/server
- âœ… **Private** - Data never leaves your infrastructure
- âœ… **Works Offline** - No internet required after model download
- Models: Sentence Transformers (embeddings), TinyLlama/Mistral (text generation)

**2. OpenAI (Optional - Paid API)**
- Better quality explanations
- Faster API responses
- Requires API key and internet

### Configuration

In `.env` file:
```env
# Use Hugging Face (Free, Local)
AI_PROVIDER=auto

# Or explicitly use Hugging Face
AI_PROVIDER=huggingface

# Or use OpenAI (requires API key)
AI_PROVIDER=openai
OPENAI_API_KEY=your-key-here
```

### Cost Optimization

- **Hugging Face**: Completely free, runs locally
- **OpenAI**: Aggressive caching (24-hour TTL for embeddings)
- Hash-based cache keys
- Batch processing
- Fallback models when appropriate

## ğŸ“ˆ Scaling Strategy

HireLens AI is designed to scale from 100 to 1 million users:

- **100 users**: Single server, current architecture
- **10k users**: Horizontal scaling, read replicas, Redis cluster
- **1M users**: Microservices, multi-region, distributed database

See [Scaling Documentation](./docs/scaling.md) for detailed strategy.

## ğŸ› ï¸ Development

### Backend Development

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Configure .env file in project root
# Set AI_PROVIDER=auto for Hugging Face (free, local)

# Run migrations
alembic upgrade head

# Initialize database
python scripts/init_db.py

# Run server
uvicorn app.main:app --reload
```

**Note**: First time running with Hugging Face will download models (~100MB-1GB). This happens automatically.

### Frontend Development

```bash
cd frontend
npm install
npm run dev
```

### Running Tests

```bash
# Backend tests
cd backend
pytest

# Frontend tests
cd frontend
npm test
```

## ğŸ“š Documentation

- [Architecture](./docs/architecture.md): System design and architecture
- [AI Reasoning](./docs/ai_reasoning.md): AI explainability and reasoning
- [Scaling Strategy](./docs/scaling.md): Scaling from 100 to 1M users

## ğŸ¤– AI Configuration

### Using Hugging Face (Free, Local - Recommended)

```env
AI_PROVIDER=auto
# or
AI_PROVIDER=huggingface

# Models (auto-downloads on first use)
HUGGINGFACE_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
HUGGINGFACE_LLM_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0
USE_GPU=false
MODEL_DEVICE=cpu
```

**Benefits:**
- âœ… No API costs
- âœ… 100% local and private
- âœ… Works offline
- âœ… Production ready

### Using OpenAI (Optional - Paid)

```env
AI_PROVIDER=openai
OPENAI_API_KEY=your-api-key-here
```

**Benefits:**
- âœ… Better quality explanations
- âœ… Faster API responses
- âœ… No local model downloads

## ğŸ”’ Security

- JWT-based authentication
- Password hashing with bcrypt
- RBAC at service layer
- Input validation (Pydantic)
- File upload restrictions
- CORS configuration
- Rate limiting
- Audit logging

## ğŸ§ª Testing

### Backend

```bash
cd backend
pytest tests/
```

### Frontend

```bash
cd frontend
npm test
```

## ğŸ“Š Monitoring & Observability

- **Structured Logging**: JSON logs with correlation IDs
- **Health Checks**: `/health` endpoint
- **Metrics**: Prometheus-compatible (future)
- **Error Tracking**: Sentry integration (configurable)

## ğŸš§ Roadmap

### Phase 1 (Current)
- âœ… Core matching engine
- âœ… Explainable AI
- âœ… Recruiter dashboard
- âœ… Basic RBAC

### Phase 2 (Future)
- [ ] Multi-tenant SaaS
- [ ] ATS integrations (Greenhouse, Lever)
- [ ] Bias & fairness analysis
- [ ] Real-time collaboration
- [ ] Candidate feedback engine
- [ ] Advanced analytics
- [ ] Mobile app

## ğŸ¤ Contributing

This is a production-grade system. Contributions should:
- Follow existing code patterns
- Include tests
- Update documentation
- Maintain code quality standards

## ğŸ“„ License

See [LICENSE](./LICENSE) file.

## ğŸ†˜ Support

For issues, questions, or contributions, please open an issue on the repository.

## ğŸ™ Acknowledgments

Built with:
- FastAPI
- Next.js
- PostgreSQL
- Redis
- Celery
- OpenAI
- And many other open-source tools

---

**Built by engineers who understand systems, scale, and business.**
